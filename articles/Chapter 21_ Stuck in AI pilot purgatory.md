## **Stuck in AI pilot purgatory**

***Why retail AI stalls before it reaches everyday operations***

### 

*Retailers are experimenting with AI quickly, but those that benefit most are likely to be the ones that turn it from a personal helper into reliable, governed workflows.*

A few years ago, artificial intelligence in retail largely meant recommendation engines and fraud models, often built by teams with more data scientists than store managers. Today it is a browser tab. SMB businesses report using generative AI in day-to-day operations at levels that appear high by the standards of earlier workplace technologies, though precise historical comparisons are hard to make.

American employees, too, are experimenting. Microsoft’s 2024 Work Trend Index finds that 75% of knowledge workers report using generative AI at work at least a few times a year, though only about one in ten say they use it daily. In retail, where margins are thin and labor is dear, even modest productivity gains can matter.

And yet the promised transformation often arrives as a set of clever drafts. Product copy is written faster. Emails sound less frazzled. A junior analyst learns to build a formula in a spreadsheet by asking a chatbot nicely. The business, meanwhile, still misses markdown windows, still runs out of bestsellers, still carries too much dead inventory. A paradox is forming: reported adoption is rising, but impact remains uneven.

This gap is sometimes described as a cold start problem, borrowed from the language of recommender systems. In machine learning it refers to the difficulty of making good predictions when there is little data on new users or items. In retail operations it has a more human meaning. Many small and midsized retailers do not lack tools. They lack the conditions that make tools dependable: repeatable workflows, clear ownership, sensible data access, and ways to measure outcomes without flattering themselves.

### **Pilots everywhere**

“Pilot purgatory” is often framed as a technical failure, but the research literature suggests it is more accurately a management challenge. Retailers run experiments that show a model can classify return reasons, summarize customer-service tickets, or suggest new product descriptions. Many of those pilots, however, struggle to graduate into processes that run every day with predictable quality, clear escalation paths, and auditable controls. Harvard Business Review has recently argued that firms run into trouble not because they pilot too much per se, but because they underinvest in the organizational work required to scale and capture value. The point is not to pilot less. It is to pilot with intent.

The pull toward endless experimentation is understandable. Generative AI is easy to try and awkward to ignore. It is also, at the outset, cheap. Friction tends to arrive later, when a “helpful” draft becomes a system change. Who approves the output? Who is accountable when it is wrong? Which data is the model allowed to see, and which is off limits? Where is the log that shows what happened, and when?

The broader evidence base is equally unromantic. McKinsey’s 2024 survey found that 70% of so-called high performers reported difficulties with data, including governance and integration into AI models. Gartner goes further, predicting that through 2026 organizations will abandon 60% of AI projects unsupported by “AI-ready” data. In retail, where information is scattered across e-commerce platforms, point-of-sale systems, email threads, vendor portals, and warehouse tools, “AI-ready” can feel like a polite synonym for “not yet.”

### **The productivity mirage**

Another trap is quieter. AI becomes a personal productivity layer rather than an organizational capability. Workers use it to draft emails, brainstorm, rewrite product copy, and generate snippets of code. Those gains can be real. In a large field experiment at a customer-support firm, a generative AI assistant increased productivity by about 14% on average, with much bigger gains for novices. A separate experiment on professional writing tasks found large time savings and improvements in output quality for participants using ChatGPT. These are meaningful results. They are also easy to overinterpret.

Retail advantage is rarely determined by who can write the crispest internal update. It is shaped by who can make thousands of small decisions reasonably well: how to set replenishment rules, how to handle returns without hemorrhaging cash, how to respond to demand spikes, how to keep the site healthy, how to price without teaching customers to wait for discounts. If AI only speeds up the thinking around those decisions, the company may become a faster version of its old self. That can be useful, but it is not necessarily a strategy.

The managerial problem is that “personal productivity” does not automatically translate into enterprise value. Work may be faster, but the process is unchanged. The email is drafted in seconds, then sits for days awaiting approval. The product description is generated, then copied into a content-management system by hand. A returns-classification model flags the problem, then disappears into a spreadsheet no one owns. Waiting becomes more efficient. The business does not.

### **From prompts to plumbing**

The difference between novelty and capability is orchestration: AI embedded into workflows that move work through the business, with explicit controls and approval points. Andrew Ng’s description of “agentic workflows,” in which a model breaks a task into steps and iteratively refines the output, captures this shift from a single prompt to a controlled, multi-step process. The term sounds grand; the reality is often mundane. It means an AI output is routed into the right system, checked against rules, and either applied or escalated. It means that “who owns this” has an answer that is not “somebody in marketing.”

For retailers, the temptation is to treat orchestration as a tooling problem. Buy the right “AI agent” and let it loose. Research and experience suggest that tends to end badly. Gartner’s warning about abandoned projects reflects governance and data management as much as model performance. Orchestration requires process engineering and risk controls that are part of daily work, not a quarterly compliance exercise.

It also imposes a hard constraint. Many of the most tantalizing uses of AI involve taking actions: changing a price, refunding an order, emailing a customer, reordering stock, pausing an ad campaign. Acting is risk. Even in relatively safe domains, a model can misunderstand context, confuse two customers, or misread a return policy. That is why, in practice, orchestration often begins with “suggest, then approve.” It feels less futuristic, but it is how organizations learn to trust automation.

### **The platform play**

One way to reduce cold-start friction is to embed AI inside the tools retailers already use, rather than bolt on a new layer of software. Shopify’s Sidekick offers a useful illustration. It is an AI-enabled commerce assistant inside Shopify’s admin interface, trained on Shopify’s features and operating within the context of a merchant’s shop. Shopify emphasizes a key guardrail: Sidekick is not allowed to make changes without the merchant’s approval and presents options for review. It is less an “autonomous agent” than a fast, context-aware colleague.

The details matter. Sidekick is available from any page of the Shopify admin through a chat interface. It includes features designed to supply context, such as attaching files from Shopify admin, mentioning specific products or orders, and a “Target mode” that lets users select elements directly. It also includes memory and personalization features, with a toggle to turn memory off for a session. In other words, it is not just a chatbot that knows a lot. It is a chatbot plugged into where work happens, with a growing set of rails around it.

That posture has advantages for mid-sized firms. Procurement is easier because the capability arrives as part of a platform they already pay for. Identity and access controls are often already in place. Training can be tied to existing workflows. Most importantly, context is not an afterthought. The assistant sits where the data and the actions live.

Large retailers are pursuing similar ideas in their own ways, often by redesigning content or process pipelines. Zalando, a European fashion e-commerce firm, launched its AI-powered fashion assistant in April 2024 and has used generative AI to cut the production time for marketing imagery and reduce costs. The company said AI-generated content accounted for 70% of its editorial campaign images in the prior quarter. This reflects orchestration of a creative workflow: less about an isolated clever output, more about reworking the pipeline so that output arrives when it is useful.

Even outside retail, the pattern is similar. EY used Microsoft’s Power Platform to automate customer payment processing and reported increasing the share of payments automatically matched and cleared from 30% to 80%, with an estimate of roughly 230,000 hours saved annually. This example is best read as an analogy, not a prescription for retailers. The broader lesson is that the largest gains tend to come when automation is built into the workflow, not sprinkled on top.

### **The catch**

Embedded AI has a darker side: it nudges firms toward dependence on platforms. When assistants live inside your commerce system, productivity gains become tied to a vendor’s roadmap, pricing, and data policies. For SMB retailers that may be an acceptable trade-off. For larger firms it raises familiar questions about lock-in and bargaining power.

There is also a cultural risk. Orchestration can look like control, and control can feel like surveillance. If AI outputs are logged, evaluated, and tied to performance metrics, workers may feel monitored rather than supported. Gallup’s data suggests that managerial support and strategic integration shape employee usage. The implication is awkward: the same governance that makes AI safer and more scalable can also make it feel imposed.

A final complication is that the “cold start” is not only technical. It is psychological. People need permission to change how they work, and clarity about when not to. A retailer that cannot decide who may edit pricing rules will not suddenly be comfortable letting a model suggest them. A firm that cannot agree on a single source of truth for inventory will not benefit from an assistant that can eloquently explain conflicting numbers.

The next 12 to 24 months are unlikely to be decided by which model a retailer chooses. That competition is noisy and, for many users, increasingly commoditized. The contest that matters is managerial: who can move from personal productivity to workflow redesign, without drowning in tools or waving away risk. The winners will not be those with the flashiest demos. They will be those with the boring capabilities that make automation trustworthy: data discipline, clear decision rights, simple controls, and a handful of workflows redesigned end to end.

Retailers will still run pilots. They should. But the question will change. It will no longer be, “Can AI do this task?” It will be, “Can this AI-enabled task be performed the same way, by many people, on many days, with predictable quality and controllable risk?” Firms that can answer yes are more likely to exit purgatory. Those that cannot will remain where many are now: surrounded by clever drafts, still waiting for a system.

### 

### **Footnotes**

Microsoft, “Work Trend Index 2024: Copilot is Your License to Innovate,” May 2024\.

Yehuda Koren, Robert Bell, and Chris Volinsky, “Matrix Factorization Techniques for Recommender Systems,” IEEE Computer, August 2009\.

Goutam Challagalla, Mahwesh Khan, and Fabrice Beaulieu, “Stop Running So Many AI Pilots,” *Harvard Business Review*, November–December 2025\.

Alex Singla et al., “The state of AI in early 2024: Gen AI adoption spikes and starts to generate value,” McKinsey, May 30, 2024\.

Gartner, “Lack of AI-Ready Data Puts AI Projects at Risk,” press release, February 26, 2025\.

Erik Brynjolfsson, Danielle Li, and Lindsey R. Raymond, “Generative AI at Work,” NBER Working Paper No. 31161, 2023\.

Shakked Noy and Whitney Zhang, “Experimental Evidence on the Productivity Effects of Generative Artificial Intelligence,” MIT Economics, March 2023\.

Andrew Ng, “Andrew Ng on Agentic AI Systems: The Next Big Leap,” Sequoia AI Ascent, April 16, 2024\.

Shopify Help Center, “Sidekick.”

Shopify Help Center, “Getting started with Sidekick.”

*The Business of Fashion*, “Zalando Launches AI Assistant for Personalized Fashion Discovery,” April 24, 2024\.

Reuters, “Zalando uses AI to speed up marketing campaigns, cut costs,” May 7, 2025\.

Microsoft Learn, “EY uses Power Platform to automate customer payment processing,” February 3, 2025\.

Gallup, “AI Use at Work Rises,” December 2025\.  
