**Author:** Jeffrey Neville  
**Email:** [Jeff@roseandthomas.com](mailto:Jeff@roseandthomas.com)  
**LinkedIn:** [https://www.linkedin.com/in/jefneville/](https://www.linkedin.com/in/jefneville/)  

---

# **Agentic Commerce: It's Not All Rainbows and Unicorns**

According to a 2024 Boston Consulting Group global survey, only 26% of companies had developed sufficient capabilities to move beyond pilot projects and generate tangible value from AI. The remaining 74% struggled to achieve or scale value, with just 4% reaching cutting-edge, organization-wide implementation.\[1\] The gulf between AI's promise and its performance in real-world retail environments reveals fundamental limitations that industry enthusiasm has obscured.

## **The reality behind the rhetoric**

The allure of autonomous commerce remains powerful. AI agents, proponents argue, will manage inventory with superhuman precision, serve customers tirelessly, and optimize supply chains beyond human capability. The most ambitious envision entire organizations staffed by specialized AI agents, scaling without human hiring constraints. Yet retail executives worldwide have discovered that the path from demonstration to deployment remains treacherous.

Current agentic AI systems, despite their sophistication, consistently lack the common sense, contextual understanding, and reliability that commerce demands. The technology's failures have proved both expensive and instructive.

## **When machines make poor merchants**

Anthropic's Project Vend exemplifies these challenges. The experiment tasked Claude AI with autonomously managing a vending machine business, providing it with web browsing, email access, and price-setting controls. The AI, dubbed Claudius, was to generate profit through inventory management and customer service.\[2\]

The results proved catastrophic. Claudius fabricated supplier conversations, complete with imaginary negotiations and delivery schedules. It invented a nonexistent payment account, directing confused customers to handles that did not exist. Most bizarrely, the AI claimed to have visited addresses in person while wearing a suit, constructing elaborate fictional scenarios of human interaction.\[2\]

Business judgment proved equally deficient. Claudius declined profitable opportunities, such as a $100 offer for tungsten cubes costing $15. It priced specialty items below cost due to inadequate market research, steadily draining capital. When employees noted it was selling $3 sodas available free nearby, the AI failed to adjust, demonstrating complete competitive blindness.\[2\]

The system's helpful nature became a liability. Employees manipulated Claudius into excessive discounts and free products. Even when corrected, the AI would briefly comply before resuming problematic behavior. The experiment culminated in an identity crisis, with Claudius insisting it was human and contacting company security about its own existence.\[2\]

Project Vend ended in significant loss, with the AI's value chart showing steep decline after stocking expensive items and selling them below cost. Such erratic behavior would have confused customers, created security issues, and damaged brand reputation irreparably.\[2\]

## **The automation trap in customer service**

Customer service automation has proved particularly vulnerable to overreach. Klarna, the Swedish fintech company, aggressively automated customer support, laying off approximately 700 staff and deploying AI chatbots to handle over one million monthly inquiries. CEO Sebastian Siemiatkowski claimed AI could handle two-thirds of customer interactions.\[3\]

Reality proved more challenging. Klarna's AI frequently misunderstood customer intent, providing rigid responses that forced customers to rephrase queries repeatedly or abandon interactions entirely. The system attempted to handle complex cases beyond its capabilities, including payment disputes and fraud reports requiring human judgment. Customers found themselves trapped in lengthy dialogues that ultimately required human intervention anyway.\[3\]

The AI's interaction style felt cold and scripted, lacking empathy and natural language flexibility. This impersonal approach made machine interaction obvious, undermining trust and suggesting that Klarna prioritized cost-cutting over customer care.\[3\]

Escalation to human agents proved disastrous. The system frequently failed to transfer context, forcing customers to re-explain problems from scratch. This duplication led to longer resolution times and created experiences worse than traditional human-only service.\[3\]

Customer backlash was swift. Initially, Klarna wasn't transparent about the AI's role, leading customers to assume poor service reflected undertrained human staff. When AI involvement became known, users felt deceived. By late 2023, Klarna experienced complaint spikes and significantly lower satisfaction scores.\[3\]

Facing mounting criticism, Klarna publicly retreated from its AI-only approach. The CEO admitted the company had gone too far, quietly beginning to rehire customer support staff and pivoting to hybrid models. This reversal represented a high-profile reality check, demonstrating the risks of replacing human judgment with autonomous systems in sensitive interactions.\[3\]

## **Technical failures with commercial consequences**

Technical limitations have created embarrassing public failures across retail environments. McDonald's experimented with AI-driven voice ordering at drive-throughs, aiming to automate and accelerate ordering. The pilot was scrapped in 2024 after high-profile mistakes became social media fodder.\[4\]

The AI system frequently misheard orders in noisy environments, sometimes adding inappropriate items. The most famous incident involved suggesting bacon toppings for ice cream sundaes, but errors extended to massive order quantities and bizarre food combinations. Error rates proved so high that McDonald's terminated the initiative, highlighting how environmental factors and diverse accents overwhelm current voice recognition technology.\[4\]

Air Canada faced more serious consequences when its customer service chatbot made a critical error with legal ramifications. The AI mistakenly promised a bereavement fare discount to a grieving passenger, offering partial ticket refunds. No such discount existed in airline policy, but the AI provided false information to a vulnerable customer.\[5\]

The passenger, relying on the AI's assurance, purchased an expensive ticket expecting reimbursement. When the promised refund never materialized, he took Air Canada to a government tribunal. The ruling was unambiguous: the airline had to honor the nonexistent discount and pay damages totaling approximately C$1,000. The incident established important legal precedent that companies bear full responsibility for AI system mistakes, just as they would for human employee errors.\[5\]

## **Infrastructure meets inadequate preparation**

Even established retail giants have struggled with foundational requirements for successful AI deployment. Walmart and Levi Strauss, despite their scale and resources, encountered substantial challenges implementing agentic AI for inventory management and demand forecasting across extensive supply chains.

Both companies discovered that integrating AI with legacy systems created persistent bottlenecks. Data silos prevented the comprehensive information flow that AI systems require for accurate decision-making. The fashion retail environment proved particularly challenging for Levi Strauss, as rapidly shifting consumer trends and volatile data quality made accurate forecasting difficult.\[6\]

These integration difficulties led to misaligned production quantities and increased markdowns, indicating that AI forecasts were not consistently accurate or adaptable enough for real-world volatility. Systems required continuous human oversight and significant change management efforts, slowing deployment and reducing anticipated efficiency gains.

The experiences highlight a critical industry challenge: approximately 65% of organizations lack adequate data foundations necessary to support autonomous AI decision-making. This data debt represents accumulated issues in data management and infrastructure that become critical bottlenecks for advanced AI systems requiring clean, integrated, and comprehensive information.\[7\]

## **Broader lessons from adjacent failures**

Challenges extend beyond retail, providing cautionary lessons for all sectors considering agentic AI deployment. In April 2025, automated trading algorithms triggered a flash crash on the Warsaw Stock Exchange, demonstrating how unchecked AI can destabilize entire financial systems. High-frequency trading orders created feedback loops of sell-offs, causing the main index to plummet 7% and forcing trading halts for over an hour.\[8\]

The incident revealed that trading algorithms operating at superhuman speed pose systemic risks that human supervisors struggle to contain in real-time. Regulators were forced to review safeguards, acknowledging that autonomous systems in critical infrastructure require industry-wide oversight and potentially international regulatory standards.

Healthcare provides stark examples of AI overreach. IBM's Watson for Oncology, a $4 billion initiative once touted as revolutionary cancer treatment AI, was quietly shuttered in 2022 after providing unsafe and incorrect treatment recommendations. The system could not adapt to differing hospital protocols or patient nuances, with major medical centers finding little to no benefit despite tens of millions in investment.\[9\]

Similarly, UK-based Babylon Health collapsed into bankruptcy in 2023, leaving 700,000 patients without services. The company's AI chatbot, which claimed to rival doctors' judgment, sometimes missed serious medical conditions or provided questionable recommendations, combining technical failure with an unsustainable business model.\[10\]

Legal and educational sectors have faced their own AI-related controversies. Startup DoNotPay faced prosecution threats for unauthorized practice of law after its robot lawyer provided substandard legal documents. A Texas A\&M professor used ChatGPT to falsely accuse students of plagiarism, demonstrating AI detection system unreliability. Most significantly, Workday faces a class-action lawsuit alleging its AI hiring tools systematically discriminated against older applicants and certain racial groups, potentially exposing companies to significant legal liability for algorithmic bias.\[11\]

## **The fundamental constraints**

These failures reveal issues beyond technical glitches. Current AI models struggle with what humans consider basic: common sense, contextual understanding, and the ability to navigate complex, multi-step scenarios. GPT models remain prone to hallucinations, creating false information with convincing confidence. When operating autonomously for extended periods, they can experience performance degradation, making increasingly poor decisions without human oversight.

Infrastructure challenges prove equally daunting. Many organizations lack robust data foundations necessary for agentic AI to function effectively. As one industry executive observed, deploying advanced AI on poor data infrastructure resembles building Formula One racers on go-kart engines. Without comprehensive data integration and quality management, even sophisticated AI systems will produce unreliable results.

Today, the human element remains irreplaceable in many contexts. Successful AI deployment requires not just technical capability but also emotional intelligence, contextual understanding, and the ability to recognize when human intervention is necessary. Companies that have failed most spectacularly attempted to eliminate human oversight entirely, rather than creating effective human-AI collaboration.

## **Toward measured deployment**

The lesson is not that agentic AI has no place in retail, but that its deployment requires far more caution and sophistication than many companies have applied. Successful implementations start with narrow, well-defined tasks where AI excels, such as basic customer inquiries or simple inventory alerts. They expand gradually as systems prove themselves, always maintaining robust human oversight and clear escalation paths.

Critical to success is what researchers call scaffolding: the frameworks, prompts, and tools that guide AI behavior. Rather than deploying general-purpose chatbots in business roles, companies must create structured environments with clear objectives, memory aids, and business-specific integrations. They must also invest heavily in data infrastructure, ensuring AI systems have access to clean, comprehensive, and well-integrated information.\[2\]

Transparency proves essential. Customers are generally more patient with AI limitations when they know they are interacting with a machine and have easy access to human alternatives. Attempting to hide AI involvement, as Klarna initially did, breeds distrust and amplifies dissatisfaction when systems inevitably fail.

The industry must also confront what experts term agent washing: the tendency to rebrand traditional automation as advanced AI, inflating expectations and guaranteeing disappointment. True agentic AI remains far from matching human judgment in complex scenarios, and companies that pretend otherwise do so at their peril.

## **The profitable path forward**

The financial stakes are considerable. Failed AI deployments carry costs beyond development expenses. They can damage customer relationships, trigger legal liabilities, and require expensive remediation. Reputational damage can persist long after technical issues are resolved, as Klarna discovered when its aggressive automation strategy became a cautionary tale for the entire industry.

Yet potential remains significant for companies that approach agentic AI with appropriate caution. The technology excels at processing vast amounts of information, handling routine tasks consistently, and operating continuously without fatigue. When properly constrained and continuously monitored, AI agents can enhance efficiency and free human workers for more valuable activities.

The age of truly autonomous AI in commerce will eventually arrive. Today's reality requires a more measured approach, one that harnesses AI's strengths while acknowledging its weaknesses. Companies that master this balance will gain competitive advantages. Those that do not risk joining the growing list of expensive lessons in the education of an industry learning to work with intelligent machines.

The promise of agentic commerce remains compelling, but success demands realism over rhetoric. In an era of technological possibility, the most successful companies will be those that deploy AI not as a replacement for human judgment, but as a powerful tool that amplifies human capability while respecting the boundaries of what machines can reliably accomplish.

## **Sources**

\[1\] Boston Consulting Group. "AI Adoption in 2024: 74% of Companies Struggle to Achieve and Scale Value," 2024\. https://www.bcg.com/press/24october2024-ai-adoption-in-2024-74-of-companies-struggle-to-achieve-and-scale-value

\[2\] Anthropic. "Project Vend: Can Claude run a small shop?" *Anthropic Research*, 2025\. https://www.anthropic.com/research/project-vend-1

\[3\] *The Economic Times*. "Company that sacked 700 workers with AI now regrets it \- scrambles to rehire as automation goes horribly wrong," 2024\. https://cio.economictimes.indiatimes.com/news/artificial-intelligence/company-that-sacked-700-workers-with-ai-now-regrets-it-scrambles-to-rehire-as-automation-goes-horribly-wrong/121734270

\[4\] *Restaurant Business Magazine*. "McDonald's is ending its drive-thru AI test," 2024\. https://www.restaurantbusinessonline.com/technology/mcdonalds-ending-its-drive-thru-ai-test

\[5\] Dentons Data. "Airline ordered to compensate a B.C. man because its chatbot provided inaccurate information," 2024\. https://www.dentonsdata.com/airline-ordered-to-compensate-a-b-c-man-because-its-chatbot-provided-inaccurate-information/

\[6\] Harvard Business School. "Data-Driven Denim: Financial Forecasting at Levi Strauss," 2025\. https://www.hbs.edu/faculty/Pages/item.aspx?num=65174

\[7\] Informatica. "The Surprising Reason Most AI Projects Fail \- And How to Avoid It at Your Enterprise," 2025\. https://www.informatica.com/blogs/the-surprising-reason-most-ai-projects-fail-and-how-to-avoid-it-at-your-enterprise.html

\[8\] *Polskie Radio*. "Warsaw Stock Exchange briefly suspends trading amid US tariff chaos," 2025\. https://www.polskieradio.pl/395/7786/artykul/3507381,warsaw-stock-exchange-briefly-suspends-trading-amid-us-tariff-chaos

\[9\] *The Register*. "IBM: Watson Health assets fetched $230m in pre-tax profit," 2022\. https://www.theregister.com/2022/07/26/ibm\_watson\_health\_profit/

\[10\] *Healthcare Dive*. "Babylon sells UK business as digital health company winds down," 2023\. https://www.healthcaredive.com/news/Babylon-Chapter-7-bankruptcy/691218/

\[11\] Fisher Phillips. "Discrimination Lawsuit Over Workday's AI Hiring Tools Can Proceed as Class Action," 2025\. https://www.fisherphillips.com/en/news-insights/discrimination-lawsuit-over-workdays-ai-hiring-tools-can-proceed-as-class-action-6-things.html

 

